{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. AWS Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Cloud Computing?\n",
    "\n",
    "Cloud Computing consists of accessing virtualised resources over the network (e.g. a website online). \n",
    "\n",
    "AWS, Azure, Google Cloud are some of the big names in the Public Cloud Computing environment.\n",
    "\n",
    "**Cloud Computing for AWS**:\n",
    "\n",
    "\"Cloud Computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing. Instead of buying, owning, and maintaining physical data centers and servers, you can access technology services, such as computing power, storage, and databases, on an as-needed basis from a cloud provider like Amazon Web Services (AWS)\"\n",
    "\n",
    "*Benefits:*\n",
    "\n",
    "* Agility: You can deploy technology services in a matter of minutes, and get from idea to implementation several orders of magnitude faster than before.\n",
    "\n",
    "* Elasticity: You provision the amount of resources that you actually need. You can scale these resources up or down to instantly grow and shrink capacity as your business needs change.\n",
    "\n",
    "* Cost savings: The cloud allows you to trade capital expenses (such as data centers and physical servers) for variable expenses, and only pay for IT as you consume it.\n",
    "\n",
    "* Deploy globally in minutes: You can deploy your application in multiple physical locations with just a few clicks. \n",
    "\n",
    "*Types of cloud computing:*\n",
    "\n",
    "* **Infrastructure as a Service (IaaS)**: Provides access to networking features, computers (virtual or on dedicated hardware), and data storage space. Similar to existing IT services. EC2 services of AWS are an example of IaaS.\n",
    "\n",
    "* **Platform as a Service (PaaS)**: Removes the need for managing underlying infrastructure (usually hardware and operating systems), and allows to focus on the deployment and management of applications. AWS RDS services for Oracle Data Bases, for example.\n",
    "\n",
    "* **Software as a Service (SaaS)**: Provides a complete product that is run and managed by the service provider. You don't have to think about maintaining the service or the underlying infrastructure but about how to use that particular service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Free Tier\n",
    "\n",
    "**AWS Regions and Zones:**\n",
    "\n",
    "AWS has presence in so many regions, within which there are multiple zones:\n",
    "\n",
    "* Region -> Country\n",
    "\n",
    "* Zone -> Multiple (clustered) Data Centers\n",
    "\n",
    "\"The AWS Cloud spans 102 Availability Zones within 32 geographic regions around the world, with announced plans for 12 more Availability Zones and 4 more AWS Regions in Canada, Malaysia, New Zealand, and Thailand.\" October, 2023\n",
    "\n",
    "-> https://aws.amazon.com/about-aws/global-infrastructure/\n",
    "\n",
    "**AWS Global Infrastructure:**\n",
    "\n",
    "* High availability through multiple Availability Zones\n",
    "\n",
    "* Improving continuity with replication between Regions\n",
    "\n",
    "* Meeting compliance and data residency requirements\n",
    "\n",
    "* Geographic expansion \n",
    "\n",
    "**Availability Zones:**\n",
    "\n",
    "![](https://docs.aws.amazon.com/images/whitepapers/latest/get-started-documentdb/images/regions-and-zones.png)\n",
    "\n",
    "* When you launch a VM (instance), you can select an Availability Zone or let AWS choose for you.\n",
    "\n",
    "* When designing your apps, you can distribute your instances across multiple Availability Zones, so in case one instance fails, an instance in another Availability Zone handles requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AWS Platform\n",
    "\n",
    "Connect to the AWS platform using your root account and check the available services. \n",
    "\n",
    "AWS has so many services, but we will focus on **sysops and devops** services and some **developer** services:\n",
    "\n",
    "**Compute**:\n",
    "\n",
    "* *EC2*: Virtual Servers in the cloud\n",
    "\n",
    "* *Elastic Beanstalk*: Run and manage Web Apps\n",
    "\n",
    "**Storage**:\n",
    "\n",
    "* *S3*: Scalable Storage in the cloud\n",
    "\n",
    "* *EFS*: Managed File Storage for EC2\n",
    "\n",
    "* *S3 Glacier*: Archive Storage in the cloud\n",
    "\n",
    "**Database**:\n",
    "\n",
    "* *RDS*: Managed Relational Database Service\n",
    "\n",
    "* *ElastiCache*: In-memory cache\n",
    "\n",
    "**Networking & Content Delivery**:\n",
    "\n",
    "* *VPC*: Isolated Cloud Resources\n",
    "\n",
    "* *CloudFront*: Global Content Delivery Network\n",
    "\n",
    "* *Route 53*: Scalable DNS and Domain Name Registration\n",
    "\n",
    "**Developer Tools**:\n",
    "\n",
    "* *CodeCommit*: Store code in private Gir repositories\n",
    "\n",
    "* *CodeArtifact*: Secure, scalable and cost-effective artifact management for software development\n",
    "\n",
    "* *CodeBuild*: Build and test code\n",
    "\n",
    "* *CodeDeploy*: Automate code deployments\n",
    "\n",
    "* *CodePipeline*: Release software using Continuous Delivery\n",
    "\n",
    "**Management & Governance**:\n",
    "\n",
    "* *CloudWatch*: Monitor resources and applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 Services\n",
    "\n",
    "EC2: Amazon Elastic Compute Cloud\n",
    "\n",
    "**Features**:\n",
    "\n",
    "* EC2 provides web services API for provisioning, managing and deprovisioning virtual servers inside Amazon cloud.\n",
    "\n",
    "* Ease in scaling up/down: e.g., scale RAM from 8Gb to 16Gb or viceversa\n",
    "\n",
    "* Pay only for what you use\n",
    "\n",
    "* Can be integrated into several other services, e.g. S3\n",
    "\n",
    "**Pricing**:\n",
    "\n",
    "1. On Demand: Pay per hour or seconds\n",
    "\n",
    "2. Reserved: Reserve capacity (for 1 or 3 years) for discounts\n",
    "\n",
    "3. Spot: Bid your price for unused EC2 capacity; but if someone outbids you, your EC2 instance will be gone.\n",
    "\n",
    "4. Dedicated Hosts: Dedicate a complete physical server for you (very expensive)\n",
    "\n",
    "**Components**:\n",
    "\n",
    "To launch an EC2 instance, you need:\n",
    "\n",
    "* Amazon Machine Image (AMI): provides the information required to launch an instance, which is a virtual server in the cloud (similar to Vagrant boxes)\n",
    "\n",
    "* Instance type: when you launch an instance, the instance type that you specify determines the hardware of the host computer used for your instance: size of the instance, computing resources: CPU, RAM, network, etc.\n",
    "\n",
    "* Amazon Elastic Block Store (EBS): provides a flexible, cost effective and easy-to-use data storage options for your instances (virtual hard disks on which you can store your OS)\n",
    "\n",
    "* Tags: simple label consisting of a customer-defined key and an optional value that can make it easier to manage, search for and filter resources\n",
    "\n",
    "* Security Group: a security group acts as a virtual firewall that controls the traffic for one or more instances\n",
    "\n",
    "* Key-pairs: EC2 uses public-key cryptography to encrypt and decrypt login information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to create an EC2 instance\n",
    "\n",
    "1. Login to your AWS Console\n",
    "\n",
    "2. Select the region: usually North Virginia (us-east1) since it is less costly\n",
    "\n",
    "3. Search for the EC2 service\n",
    "\n",
    "4. Click on Instances (in the left part) and the Launch Instances button\n",
    "\n",
    "5. Give name and tags and select the Amazon Machine Image (AMI): browse for the OS you prefer, be careful with free-tier alternatives as they may charge you after some time.\n",
    "\n",
    "6. Check the instance type: select t2.micro since it is included in the free tier version. Some documentation on the instance types: https://aws.amazon.com/ec2/instance-types/\n",
    "\n",
    "7. Set a key pair login using \"Create new key pair\", give a name and keep in RSA and .pem formats\n",
    "\n",
    "8. In Network settings, create a new security group by editing the current settings: change the name of the security group and the description. Also, in security group rule 1, change Source type for \"My IP\". Additional, in advanced settings, go to \"User data\" and add the provisioning for the instance:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "sudo yum install httpd -y\n",
    "sudo systemctl start httpd\n",
    "sudo systemctl enable httpd\n",
    "mkdir /tmp/test1\n",
    "```\n",
    "\n",
    "9. Click on Launch Instance\n",
    "\n",
    "10. Check the status of the instance (Instance state and Status check). If you select the instance, you can check its public and private IP addresses. Also, you can connect to it by clicking on Connect.\n",
    "\n",
    "11. In the Connect to instance page, select the \"SSH client\" tab and follow the steps. Use the key (.pem file) downloaded when setting the key pair login (`web-dev-key.pem`), the user (`ec2-user`) and the public DNS name (`ec2-50-17-123-122.compute-1.amazonaws.com`):\n",
    "\n",
    "`ssh -i \"web-dev-key.pem\" ec2-user@ec2-50-17-123-122.compute-1.amazonaws.com`\n",
    "\n",
    "12. Open Git Bash and go to the directory where the .pem file is dowloaded or stored. Then, copy and paste the complete command as shown in step 11. You should be able to connect to the instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the `httpd` service\n",
    "\n",
    "* Provisioning was included in the creation of the instance, so the `httpd` service should be running. Check it by running the command `systemctl status httpd`\n",
    "\n",
    "* Check connection through port 80 is related to httpd: `ss -tunlp | grep 80`\n",
    "\n",
    "* You can try and connect through the public IP address to see if the connection is given. The problem is that the initial security rule for the instance only allowed connections through port 20.\n",
    "\n",
    "* Go to the security tab in your instance and click the security group. Go to Inbound Rules and modify them by clicking on Edit Inbound Rules.\n",
    "\n",
    "* Add a new rule to allow connections through port 80:\n",
    "\n",
    "    Type: Custom TCP; Port range: 80; Source: My IP/Anywhere IPv4/Anywhere IPv6\n",
    "\n",
    "* Save changes and try to connect again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminate an instance\n",
    "\n",
    "In the section \"Instances\", select the instance and click on Instance state button. Select \"Terminate instance\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices of EC2 Instance Creation\n",
    "\n",
    "1. Gather the computing requirements:\n",
    "\n",
    "    - OS to choose: CentOS, Ubuntu? -> AIM to go with\n",
    "\n",
    "    - Size: RAM, CPU, Network -> Instance type\n",
    "\n",
    "    - Storage: for OS and applications \n",
    "\n",
    "    - Project information -> Tagging\n",
    "\n",
    "    - Services/Apps running: SSH, HTTPD, MySQL, etc.\n",
    "\n",
    "    - Environment: Development, QA, Staging, preproduction, production, etc.\n",
    "\n",
    "    - Login User/Owner -> Tagging and tracking\n",
    "\n",
    "2. Create the key pairs\n",
    "\n",
    "3. Create the security group (firewall)\n",
    "\n",
    "4. Start launching the instance: select your security group, key-pair and make all the decisions based on your requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT INFO ON SECURITY GROUPS**:\n",
    "\n",
    "A security group acts as a virtual firewall that controls the traffic for one or more instances.\n",
    "\n",
    "* Firewall is a network security system that monitors and controls incoming and outgoing network traffic. Think of it as the gatekeeper who has a register of who's allowed to come in and also who is allowed to go out.\n",
    "\n",
    "You can *add rules* to each security group that **allow traffic to or from its associated instances**\n",
    "\n",
    "Security groups are \"stateful\" -> Outbound rules are updated when inbound rules are added/modified.\n",
    "\n",
    "Two types of rules:\n",
    "\n",
    "* Inbound rules: Traffic coming from outside on the Instance\n",
    "\n",
    "* Outbound rules: Traffic going from Instance to outside\n",
    "\n",
    "Allowing every IP address to access every port of an Instance IS NOT A GOOD PRACTICE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a Website in EC2\n",
    "\n",
    "First, enter the EC2 service:\n",
    "\n",
    "1. Check the webpage you want to set up on Tooplate: https://www.tooplate.com/view/2128-tween-agency. So project name will be **Tween Website**\n",
    "\n",
    "2. Create a key pair: Go to the menu on the left and search for Key Pairs in the *Network & Security* section. Create a key pair for development environment in North Virginia zone:\n",
    "\n",
    "    - Name: tween-dev-nvir (very helpful to have proper naming convention)\n",
    "\n",
    "    - Type: RSA (Rivest-Shamir-Adleman): \n",
    "    \n",
    "        Assymetric encryption algorithm: Given a key pair, data that is encrypted with one key can only be decrypted by the other.\n",
    "\n",
    "    - File format: .pem (container format for the key)\n",
    "\n",
    "    It will download the **private key** and the **public key** will be \"injected\" in the instance (saved in the key-pairs menu). DO NOT SAVE THE PRIVATE KEY IN GITHUB OR A PUBLIC SPACE!\n",
    "\n",
    "3. Create security group (firewall): Go to the menu on the left and search for Security Group again in the *Network & Security* section. Create a new security group:\n",
    "\n",
    "    - Name: tween-web-dev-sg\n",
    "\n",
    "    - Description: tween-web-dev-sg\n",
    "\n",
    "    - Inbound rules: Add rules:\n",
    "\n",
    "        * A rule to access SSH from My Corporate/Home IP only: \n",
    "\n",
    "            - Type: SSH, Source: My IP\n",
    "\n",
    "        * We will come back later to add rules to allow the access to the webpage.\n",
    "\n",
    "    - Outbound rules: DO NOT MODIFY!\n",
    "\n",
    "4. Go to the *Instances* section on the left and, in Instances, click on Launch Instances:\n",
    "\n",
    "    - In Name and Tags, click on Additional Values and add:\n",
    "\n",
    "        - Key: Name, Value: web01, Resource types: Instances, Volumes (virtual hard disk) & Network Interface\n",
    "\n",
    "    - Add additional tags:\n",
    "\n",
    "        * Key: Project, Value: tween\n",
    "\n",
    "        * Key: Environment, Value: prod\n",
    "\n",
    "        * Key: Owner, Value: lead-devops\n",
    "\n",
    "    - Select AMI: Ubuntu 22.04 (free tier eligible)\n",
    "\n",
    "    - Select Instance type: t2.micro (free tier eligible)\n",
    "\n",
    "    - Select Key pair: the one we created in step 2: tween-dev-nvir (creating it beforehand and selecting it here is a good practice!) \n",
    "\n",
    "        * **Important!**: One key can be used for all the instances or each and every instance can have their own keys\n",
    "\n",
    "        * The best way is to divide your key **based on the ENVIRONMENT!** e.g., one key for development, another one for QA, another key for production, ...\n",
    "\n",
    "    - Edit Network settings:\n",
    "\n",
    "        * Firewall: Click on select existing security group and select the one created in step 3.\n",
    "\n",
    "    - Go to advanced settings:\n",
    "\n",
    "        * User data: Add provisioning if required\n",
    "\n",
    "    - Go to Summary and Select the number of instances you want to create and click on Launch Instance.\n",
    "\n",
    "5. Go and select the Instance: Click on connect and copy the command to access it:\n",
    "\n",
    "    `ssh -i \"tween-dev-nvir.pem\" ubuntu@ec2-3-94-87-13.compute-1.amazonaws.com`\n",
    "\n",
    "6. Go to the directory where the `.pem` file with the private key is located using Git Bash. Paste the command to access the Instance and run it. \n",
    "\n",
    "7. Once inside the instance, you need to run the following commands to set up the website:\n",
    "\n",
    "    ```\n",
    "        sudo apt update\n",
    "        sudo apt install apache2 wget unzip -y\n",
    "        wget https://www.tooplate.com/zip-templates/2128_tween_agency.zip\n",
    "        unzip 2128_tween_agency.zip\n",
    "        cp -r 2128_tween_agency/* /var/www/html/\n",
    "        systemctl restart apache2\n",
    "    ```\n",
    "\n",
    "8. We need to access the website using port 80, so we need to add a new rule in the security group:\n",
    "\n",
    "    - Go to the Instance, select the Security tab and click on Security Groups link.\n",
    "\n",
    "    - Edit Inbound rules and add new rule:\n",
    "\n",
    "        * Type: Custom TCP, Port: 80, Source: My IP\n",
    "\n",
    "    - Save rules\n",
    "\n",
    "9. Go to the Instance page and copy the public IP address. Go to a browser and go the IP address: http://3.94.87.13 and you will find the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Static Public IP address\n",
    "\n",
    "* Start the instance by clicking on the dropdown button Instance state and then Start instance\n",
    "\n",
    "* Go to Network & Security in the side bar and search for **Elastic IPs** (5 for free, then you can purchase more)\n",
    "\n",
    "* Click on Allocate Elastic IP address, keep the region and click on Allocate.\n",
    "\n",
    "* Then, go to the dropdown button Actions and click on Associate Elastic IP address.\n",
    "\n",
    "* Tick the Instance option and select the instance in the search box. Finally, click on Associate.\n",
    "\n",
    "* Confirm the association by clicking on the instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Command Line Interface (CLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to install `awscli` using **chocolatey**: `choco install awscli -y`. The documentation is available here: https://docs.aws.amazon.com/cli/\n",
    "\n",
    "Then, go to **Git Bash** and check the version of AWS CLI you've got installed:\n",
    "\n",
    "`aws --version`\n",
    "\n",
    "To use the AWS CLI, you need to create a new user:\n",
    "\n",
    "* Go to **IAM services** > Users\n",
    "\n",
    "* Click on *Create user*: add a name and don't tick the box to provide access to the AWS Management Console. Click on Next.\n",
    "\n",
    "* In Permissions options, select *Attach policies directly*. We want to use this user for our entire AWS account, so we give (tick the following boxes):\n",
    "\n",
    "    - AdministratorAccess\n",
    "\n",
    "    - (For another user): Give access only to specific servers (S3 for example)\n",
    "\n",
    "* Click on Next and Create user\n",
    "\n",
    "* Click on the user name and go to *Security credentials*\n",
    "\n",
    "* We need to create Access keys to use it for CLI: Go to Access keys section and click on *Create access key*\n",
    "\n",
    "    - Select *Command Line Interface (CLI)*\n",
    "\n",
    "    - Tick the confirmation box and click Next, and then Create access key\n",
    "\n",
    "    - Download the .csv file with the Access keys\n",
    "\n",
    "    - DO NOT REVEAL THIS ACCESS KEY AND THE SECRET ACCESS KEY TO ANYBODY ELSE! especially when the user has administrator access\n",
    "\n",
    "* Go to Git Bash, execute `aws configure` and copy and paste the Access key and the Secret access key\n",
    "\n",
    "* Enter the Default region name: `us-east-q` and Default output format: `json`. Click Enter.\n",
    "\n",
    "* You can check this information running the command: `ls ~/.aws/`. You can check the `config` (`cat ~/.aws/config`) and `credentials` (`cat ~/.aws/credentials`) files.\n",
    "\n",
    "**Important**: All commands to create and launch a new instance are given in the **Command Reference** menu in the CLI documentation: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Block Storage (EBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EBS provides two things:\n",
    "\n",
    "* EBS volume (virtual hard disk)\n",
    "\n",
    "* Snapshot (backup of the EBS volume)\n",
    "\n",
    "EBS are:\n",
    "\n",
    "* Block-based storage (like hard disks)\n",
    "\n",
    "* Used to run EC2 OS, store data from database, file data, etc.\n",
    "\n",
    "* Placed in specific Availability Zone. Automatically replicated within the same availability zone of the instance to protect from failures.\n",
    "\n",
    "* Snapchot is used for backup of the entire volume\n",
    "\n",
    "\n",
    "### EBS Types\n",
    "\n",
    "* **General purpose (SSD)**: Used in most work loads (best combination of right price and speed)\n",
    "\n",
    "* **Provisioned IOPS**: Used to run large databases (higher input-output per seconds)\n",
    "\n",
    "* **Throughput Optimised HD**: Used for big data and data warehouses\n",
    "\n",
    "* **Cold HDD**: Use for file servers (very low-cost)\n",
    "\n",
    "* **Magnetic**: Recommended for backups and archives (the slowest!)\n",
    "\n",
    "Some more information about EBS types in: https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring EBS\n",
    "\n",
    "You can select the prefered storage configuration:\n",
    "\n",
    "* When launching an instance: \n",
    "\n",
    "    - Go to the section Configuration Storage\n",
    "    \n",
    "    - Select the type of storage in the dropdown list: default is `gp2 (general purpose)`\n",
    "\n",
    "* After launching an instance:\n",
    "\n",
    "    - Select the instance and go to the Storage tab\n",
    "\n",
    "    - In *Root device details* > *Block devices*, you find your current Volume ID and the size in GiB\n",
    "\n",
    "    - Click on the Volume ID and edit its name, according to the instance-hierarchy: e.g., web01-ROOT-volume.\n",
    "\n",
    "    **Important**: Always give proper names to your volumes for easy identification\n",
    "\n",
    "    - Both instance and volume need to be in the same availability zone so they can connect!\n",
    "\n",
    "    - To **add more storage**: Go to Elastic Block Store on the left menu > Volumes > Create Volume:\n",
    "\n",
    "        * Select volume type: `gp2`\n",
    "\n",
    "        * Size (GiB): `5`\n",
    "\n",
    "            Volumes over 30GiBs are more than the Free Tier allowance: Over 30GiB, you would need to pay!\n",
    "\n",
    "        * Availability zone: **Same as the instance you want to connect with!**\n",
    "\n",
    "        * Encryption: Tick, in case you want it encrypted\n",
    "\n",
    "        * Add Tag: \n",
    "\n",
    "            - Key: Name, Value: gymso-web01-Images (We want to create this storage for our website Image)\n",
    "\n",
    "        * Finally, click on Create Volume\n",
    "\n",
    "    - When it is created, select the volume you want to attach to an instance and click on Actions > Attach volume:\n",
    "\n",
    "        * Select the instance you want to attach the volume in the zame Availability Zone\n",
    "\n",
    "        * Click on Attach\n",
    "\n",
    "* Connect to the instance:\n",
    "\n",
    "    - `ssh -i {PATH_TO_KEY.pem} ec2-user@CURRENT.IP.0.0`\n",
    "\n",
    "    - Switch to root user: `sudo -i`\n",
    "\n",
    "    - Go to `cd /var/www/html` and find the `images` directory.\n",
    "\n",
    "* We need to partition and mount this image in our recently attached storage:\n",
    "\n",
    "    - List all the disks in the Linux instance: `fdisk -l`\n",
    "\n",
    "        * Identify the name of the partition you want to use for mounting the webpage image.\n",
    "\n",
    "        * Run `df -h`: It will show the name of the root disk with `/` in the column Mounted on.\n",
    "\n",
    "        * Once identified (`/dev/xvdf`), create a partition for the attached disk:\n",
    "\n",
    "            Run: `fdisk /dev/xvdf`\n",
    "\n",
    "            Run `m` for help\n",
    "\n",
    "            You will find that the command to add a new partition is `n`\n",
    "\n",
    "            Run command `n` > type: `p` (primary or just enter) > number: (enter) > first sector: (enter) > +size: `+3G`\n",
    "            (or just enter to create a partition of the entire disk)\n",
    "\n",
    "            Run `p`to print the partition table.\n",
    "\n",
    "            Run `w` to write and confirm!\n",
    "\n",
    "        * Check the partition in `fdisk -l`\n",
    "\n",
    "        * Format the disk using `mkfs`. \n",
    "        \n",
    "            - First, check the available formats by running `mkfs` and two times the tab key.\n",
    "\n",
    "            - Use the `.ext4` format: Run `mkfs.ext4 /dev/xvdf1`\n",
    "\n",
    "    - Mount the webpage image: \n",
    "\n",
    "        - Go to `cd /var/www/html` and find the `images` directory.\n",
    "\n",
    "        - Create a directory: `mkdir /tmp/img-backups`\n",
    "\n",
    "        - Move from `images` to `img-backups`: Run `mv images/* /tmp/img-backups/`\n",
    "\n",
    "        - Do a temporary mount: `mount /dev/xvdf1 /var/www/html/images/` (`images/` should be empty)\n",
    "\n",
    "        - Run `df -h` to check where the partition was Mounted on.\n",
    "\n",
    "        - To unmount, run: `umount /var/www/html/images`\n",
    "\n",
    "        - Do a permanent mount: Opem file `vi /etc/fstab`:\n",
    "\n",
    "            In the last line, add:\n",
    "\n",
    "            ```\n",
    "                /dev/xvdf1      /var/www/html/images        ext4    defaults    0   0\n",
    "            ```\n",
    "\n",
    "        - Run `mount -a` to mount all the entries from the `fstab` file.\n",
    "\n",
    "        - Check by running `df -h`\n",
    "\n",
    "        - Move data from the temp directory: `mv /tmp/img-backups/* /var/www/html/images/`\n",
    "\n",
    "* Once finished, restart the `httpd` service: `systemctl restart httpd` and check status: `systemctl status httpd`\n",
    "\n",
    "* See using the browser. If there's a problem with the webpage images, modify the file `vi /etc/selinux/config`:\n",
    "\n",
    "    - Modify the line to: `SELINUX=disabled`\n",
    "\n",
    "* Reboot the machine: `reboot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBS Snapshots\n",
    "\n",
    "Provides a backup mechanism for the EBS volumes: e.g., for databases.\n",
    "\n",
    "Snapshot is mostly used to take backups and restore in the event of failures. When restoring a snapshot, you should:\n",
    "\n",
    "* Unmount the partition (to prevent data from being overwritten)\n",
    "\n",
    "* Detach the volume from your instance\n",
    "\n",
    "* Create a new volume from snapshot\n",
    "\n",
    "* Attach the newly created volume\n",
    "\n",
    "* Mount it back (replace it!)\n",
    "\n",
    "### Creating a Snapshot\n",
    "\n",
    "In the Volumes section:\n",
    "\n",
    "* Select the volume you want to create a backup\n",
    "\n",
    "* Go to Actions > Create Snapshot\n",
    "\n",
    "* Give a description and a tag: Key: Name, Value: db01-volume-db-SNAP\n",
    "\n",
    "* Click on Create Snapshot\n",
    "\n",
    "* Go to Snapshots section to see the snapshot\n",
    "\n",
    "Inside the instance:\n",
    "\n",
    "* Stop the service you want to recover/replace: e.g., `systemctl stop mariadb`\n",
    "\n",
    "* Unmount the volume partition: `umount /var/lib/mysql/`\n",
    "\n",
    "* Check using `df -h`\n",
    "\n",
    "* To detach the volume partition, go to Volumes section in AWS, select the volume and click on Actions > Detach Volume\n",
    "\n",
    "* Go to Snapshot section, select the snapshot you want to recover and click on Actions > Create Volume\n",
    "\n",
    "* Apply the preferred settings: Volume Type, Size, Availability Zone, Tags, etc.\n",
    "\n",
    "* Create volume, attach volume to the instance and mount it using `mount -a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Load Balancer (ELB)\n",
    "\n",
    "When building a cluster of services (multiple servers), you need a single endpoint to access them and that's mostly provided through a **Load Balancer**.\n",
    "\n",
    "AWS provides with a Load Balancer for these situations:\n",
    "\n",
    "**Ports**:\n",
    "\n",
    "* **Frontend Port**: Listens from the User Requests on this port aka \"Listeners\" (generally on port $443$ for https)\n",
    "\n",
    "* **Backend Ports**: Services running on OS listening on this port. E.g., a Tomcat server which is running on port 8080\n",
    "\n",
    "ELB distributes incoming application or network traffic accross multiple targets, such as Amazon EC2 instances, containers, and IP addresses, in multiple availability zones.\n",
    "\n",
    "ELB supports three types of load balancers:\n",
    "\n",
    "1. Application Load Balancer: Popular for web traffic (websites, apps, http & https). It routes traffic based on advanced application level information that includes the content of the request. (Level 7)\n",
    "\n",
    "2. Network Load Balancer: Functions at the 4th layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. It gets a static IP.\n",
    "\n",
    "3. Classic Load Balancer: Simplest one. It routes traffic based on either application or network level information.\n",
    "\n",
    "    * Ideal for simple load balancing where you don't need any other complications \n",
    "\n",
    "More information on Load Balancing in: https://docs.aws.amazon.com/elasticloadbalancing/\n",
    "\n",
    "### Configuring ELB to an Instance\n",
    "\n",
    "1. Create an instance: Use the bash script in the **AWS/Load-balancer-websetup** directory as a provision: `multios_websetup.sh` to deploy the webpage. Remember to create a Key-Pair and define security groups.\n",
    "\n",
    "2. Once the instance is created and the webpage is working (check the IP), create an Amazon Machine Image (AMI) for the instance:\n",
    "\n",
    "    * Select the instance, go to Actions > Image and templates > Create image.\n",
    "\n",
    "    * Creating an image is similar to creating a *snapshot* in EBS:\n",
    "\n",
    "        - Image name: health-ami > Create image\n",
    "\n",
    "        - Go to the Images section and check AMIs\n",
    "\n",
    "    * The custom AMI with the website in it is used to launch a cluster of instances from it.\n",
    "\n",
    "3. In order to avoid all the steps of creating an instance from an image (which are the same as for creating a new instance), create a *template* to very quickly launch an instance. \n",
    "\n",
    "    * Go to Instances section and Launch Templates > Create launch template\n",
    "\n",
    "    * Launch template name: health-template, Template version description: v1\n",
    "\n",
    "    * In Application and OS Images: Select My AMIs tab and Owned by me: Your AMI from step 2 should appear here.\n",
    "\n",
    "    * Finish other settiongs:\n",
    "        \n",
    "        - Instance type: t2.micro\n",
    "        \n",
    "        - Key pair (Login): the same one created in step 1\n",
    "\n",
    "        - Network settings > Security groups: the same one created in step 1\n",
    "\n",
    "        - Resource tags: Key: Name, Value: web00, Resource types: Instances\n",
    "\n",
    "    * Create launch template\n",
    "\n",
    "4. In Launch Templates section, select the recently created template and go to Actions > Launch instance from template.\n",
    "\n",
    "    - While launching, you can modify any of the preset settings. For example, change the Name tag to web01, web02 and so on ...\n",
    "\n",
    "    - Click on Launch instance\n",
    "\n",
    "5. Now we have two instances: They cannot be accessed separately by the user, they need to be *accessed from a single endpoint* and that endpoint should **route the request** to either of these instances. That single endpoint is the *Load Balancer*\n",
    "\n",
    "    * Go to Load Balancing section > Target Groups\n",
    "\n",
    "        - Target groups is a group of instances that we want to balance with \"health checks\". \n",
    "\n",
    "        - Click on Create target group > Instances\n",
    "\n",
    "        - Give a Target group name: heath-tg, and Port (same as the instances): HTTP: 80\n",
    "\n",
    "        - Define a Health checks: \n",
    "        \n",
    "            * Health check protocol: HTTP: `/`\n",
    "\n",
    "            * Health check port: Same as instance: Traffic port (or if different, use Override)\n",
    "\n",
    "            * Healthy threshold (number of times to check if healthy): 2\n",
    "\n",
    "            * Unhealthy threshold (number of times to check if unhealthy): 2\n",
    "\n",
    "            * and so on...\n",
    "\n",
    "        - Click on Next\n",
    "\n",
    "        - Select the instances in Register targets and click on Include as pending below\n",
    "\n",
    "        - Review them in Review targets. Finally, click on Create target group.\n",
    "\n",
    "    * Go to Load Balancers in the Load Balancing section:\n",
    "\n",
    "        - Click on Create load balancer\n",
    "\n",
    "        - Select Application Load Balancer (for HTTP, HTTPS). Click on Create.\n",
    "\n",
    "        - Set the ELB:\n",
    "\n",
    "            * Name: health-elb, Scheme: internet-facing\n",
    "\n",
    "        - Define Network Mapping: Make the ELB highly available by defining two or more zones: select all the zones\n",
    "\n",
    "        - Security Groups: Click on Create a new security group:\n",
    "\n",
    "            * SG name and description: health-elb-sg\n",
    "\n",
    "            * Inbound rules: \n",
    "            \n",
    "            a. Type: Custom TCP, Port range: 80, Source: Anywhere IPv4\n",
    "\n",
    "            b. Type: Custom TCP, Port range: 80, Source: Anywhere IPv6\n",
    "\n",
    "            * Click on Create security group\n",
    "\n",
    "        - Refresh and select the recently created security group: health-elb-sg\n",
    "\n",
    "        - Listeners and routing: Protocol: HTTP, Port: 80, Default action: Forward to **health-tg** (target group created before)\n",
    "\n",
    "        - Click on Create load balancer\n",
    "\n",
    "6. Once created, you can visualise your Load Balancer. To access it, you can copy the **DNS name** and paste it on a browser. However, you will need to fix a problem first: \n",
    "\n",
    "    * The LB won't load the page with error 504 Gateway Time-out (Server error): There's something in between the instance and the load balancer that doesn't let it pass.\n",
    "\n",
    "    * Remember that every instance is protected by a Security group. That is, the *Inbound rules* of the security group for the instances need to be set so the Load balancer can access the instances.\n",
    "\n",
    "    * You can also check the Target group section: select the target group and check the Health Status column. If the instances are \"Unhealthy\", it means that the Load Balancer cannot access the group.\n",
    "\n",
    "    * So, go to Network & Security section > Security Groups: Find the security group for the instances and add a new Inbound rule:\n",
    "\n",
    "        - Type: Custom TCP, Port range: 80, Source: Custom, and search for the security group of the Load Balancer: health-elb-sg, Description: Allow port 80 from ELB\n",
    "\n",
    "    * Wait for the instances in the Target group to be healthy and go again to the DNS address given by the Load balancer. The webpage should appear now.\n",
    "\n",
    "7. To add/remove instances to a Target group:\n",
    "\n",
    "    * Add them using the Targets tab when selecting the Target group > Register targets: Select the instances and click on Include as pending below\n",
    "\n",
    "    * Remove them by selecting the instances in the Targets tab when selecting the Target group > Deregister: It will not immediately remove but drain the request first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic File System (EFS)\n",
    "\n",
    "If you have a cluster of servers and you want to store data at one centralised place, you can use EFS to for shared storage.\n",
    "\n",
    "More info on: https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Scaling\n",
    "\n",
    "Auto Scaling is a service that automatically monitors and adjusts computational resources to maintain performance for applications hosted in AWS.\n",
    "\n",
    "We need the Cloud Watch alarms to monitor the metrics for the instance.\n",
    "\n",
    "* For example, adding more CPU capacity in case the CPU utilisation is too high for a long time: with Cloud Watch alarms.\n",
    "\n",
    "* Also, you can remove capacity to keep costs low.\n",
    "\n",
    "How does it work?\n",
    "\n",
    "* Auto Scaling uses **Launch Configuration/Template** to launch EC2 instances.\n",
    "\n",
    "* Auto Scaling also uses **Scaling Policy** to increase and decrease the number of running instances in the group dynamically to meet changing conditions.\n",
    "\n",
    "![](https://docs.aws.amazon.com/images/autoscaling/ec2/userguide/images/asg-basic-arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Auto Scaling Groups\n",
    "\n",
    "We need some requirements before setting up an Auto Scaling Group:\n",
    "\n",
    "* A Launch template (We can use the one we created in the Load Balancer section)\n",
    "\n",
    "* A Load balancer (without instances yet)\n",
    "\n",
    "    - Create an empty Target group: health-tg (no instances registered)\n",
    "\n",
    "    - Create an Application Load Balancer: health-elb (You need to create a security group for the ELB and assign the Target group in the Listeners section)\n",
    "\n",
    "Once we have these requirements:\n",
    "\n",
    "* Go to the Auto Scaling Groups section and click on Create Auto Scaling group:\n",
    "\n",
    "    - Set Name: health-ASG\n",
    "\n",
    "    - Select Launch template: health-template\n",
    "\n",
    "    - After clicking Next, select the Availability Zones (all the zones), and Next again\n",
    "\n",
    "    - In Load balancing: select Attach to an existing load balancer and Choose from your load balancer target groups: select health-tg\n",
    "\n",
    "    - Health checks: Tick on the Turn on Elastic Load Balancing health checks box\n",
    "\n",
    "    - Click on Next\n",
    "\n",
    "    - Define the Group Size: Desired capacity: 2 and Scaling: Min desired: 1, Max desired: 4\n",
    "\n",
    "    - Set Automatic scaling to Target tracking scaling policy:\n",
    "\n",
    "        * Select Metric type: Average CPU utilization\n",
    "\n",
    "        * Target value: 50\n",
    "\n",
    "    - Click on Next and set notifications to the SNS Topic\n",
    "\n",
    "    - Define Tags: Key: Name, Value: webserver\n",
    "\n",
    "    - Finally, read all the setting and click on Create Auto Scaling group\n",
    "\n",
    "You can see the Auto Scaling group crated and check the different tabs (options) available:\n",
    "\n",
    "* Details: Use it to modify the Launch template. **All the modifications you do to your Auto Scaling group should be done to the Launch template**: Click on Edit and Update.\n",
    "\n",
    "* Automatic Scaling: Used to check the auto scaling policy\n",
    "\n",
    "* Instance management: Used to check the number of instances and if they are healthy or not\n",
    "\n",
    "Whenever you make changes, go to Instance refresh and click on Start instance refresh.\n",
    "\n",
    "* Set Minimum healthy percetage to 90% (Keep it higher than 80% to prevent traffic/capacity problems) \n",
    "\n",
    "**Important**: Remember these are dynamic instances. Make sure you don't store any information (dynamic information) inside instances in Auto Scaling. The storage *should be out of them by using EFS or NFS*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3: Simple Storage Service\n",
    "\n",
    "One of the most popular and oldest service of AWS.\n",
    "\n",
    "S3 is storage for the internet. You can use S3 to store and retrieve any amount of data at any time, from anywhere on the web. It's like Google Drive or Dropbox but with many features.\n",
    "\n",
    "**Basics**:\n",
    "\n",
    "* Object-based storage: files can be uploaded (pictures, videos, etc.)\n",
    "\n",
    "* Data is replicated across multiple facilities: \n",
    "\n",
    "* Unlimited storage\n",
    "\n",
    "* S3 stores data as *objects* within *buckets*\n",
    "\n",
    "* Bucket name has to be unique (we need an endpoint to access it)\n",
    "\n",
    "**Buckets**:\n",
    "\n",
    "A bucket is a logical unit of storage (container) in AWS.\n",
    "\n",
    "**Object Storage**:\n",
    "\n",
    "Computer data sotrage architecture that manages data as objects.\n",
    "\n",
    "![](https://assets.cloudacademy.com/bakery/media/uploads/lab/blobid1-c96cfbd2-5276-479f-90a1-6b13aea01d73.png)\n",
    "\n",
    "One very common use case of S3 is connecting it to EC2 instances which are running a service (e.g., web or app) and they require to store some file-based data. \n",
    "\n",
    "![](https://www.c-sharpcorner.com/article/introduction-to-aws-s3/Images/3.png)\n",
    "\n",
    "**Differences with EFS**:\n",
    "\n",
    "For EFS, we mount the File System at the OS level, i.e, there is a folder in the OS level. For S3, we are going to programmatically access and store data through the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Storage Classes\n",
    "\n",
    "![](https://static.javatpoint.com/tutorial/aws/images/aws-storage-classes.jpg)\n",
    "\n",
    "* **S3 Standard**: General-purpose storage of frequently accessed data. Fast access & object replication in multiple Availability Zones\n",
    "\n",
    "* **S3 IA (Infrequent Access)**: Long-lived, but less frequently accessed data. Slow access, object replication in multiple AZ.\n",
    "\n",
    "* **S3 One Zone-IA**: It's used for data that is accessed less frequently, but requires rapid access when needed. Slow access, no object replication.\n",
    "\n",
    "* **S3 Intelligent Tiering**: Automatically moves data to most cost effective tier.\n",
    "\n",
    "* **S3 Glacier**: Low-cost storage class for data archiving (rarely access, once per year for audit).\n",
    "\n",
    "* **S3 Glacier Deep Archive**: Lowest cost storage for long time data; retrieval time of 12 hrs.\n",
    "\n",
    "![](https://www.scaler.com/topics/images/aws-lifecycle-policies-tansition.webp)\n",
    "\n",
    "**S3 Charges**\n",
    "\n",
    "* Storage\n",
    "\n",
    "* Requests\n",
    "\n",
    "* Tiers\n",
    "\n",
    "* Data Transfer\n",
    "\n",
    "* Region Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating S3 Buckets\n",
    "\n",
    "Search for the S3 service and click on Create bucket.\n",
    "\n",
    "* General configuration:\n",
    "\n",
    "    - Check the region: The S3 bucket will be created in the region you are currently in.\n",
    "\n",
    "    - Bucket type: Use General Purpose: several availability zones\n",
    "\n",
    "    - Bucket name: It needs to be unique: s3-devops-doc\n",
    "\n",
    "* Object Ownership: Access list of AWS account users that can access the bucket.\n",
    "\n",
    "    - Select Access Control Lists (ACLs) *disabled*: private (Most of bucket permissions will be through policies). When we want the S3 bucket to be public, we will need to *enable* ACLs.\n",
    "\n",
    "* Block Public Access settings:\n",
    "\n",
    "    Whenever you upload any object in the S3 bucket, **it's by default private**. Even if you want to make it public, you cannot do it because *by default, all the public access is blocked*.\n",
    "\n",
    "    (We'll get back to this point later)\n",
    "\n",
    "* Bucket Versioning: Enable\n",
    "\n",
    "    What happens if you delete data in S3 buckets? Can you recover it? -> It depends on if you have enabled versioning. With versioning, it's super easy!\n",
    "\n",
    "* Default Encryption:\n",
    "\n",
    "    All S3 buckets are encrypted, the thing is to select the type of encryption:\n",
    "\n",
    "    - Server-side encryption with Amazon S3 managed keys (SSE-S3): Cheapest option \n",
    "\n",
    "    - Server-side encryption with AWS Key Management Service keys (SSE-KMS): Create your own encryption key. Not free! Mostly used for compliance. You own the key, so AWS doesn't have any keys.\n",
    "\n",
    "    - Dual-layer server-side encryption with AWS Key Management Service keys (DSSE-KMS): Pricing increases\n",
    "\n",
    "Finally, click on Create bucket!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading a file and Making it Public\n",
    "\n",
    "Once created, select the S3 bucket and click on Upload to upload any object (e..g, a pdf file).\n",
    "\n",
    "* When uploading, you can see the **Properties** drop-down menu and the Storage class section:\n",
    "\n",
    "    - Select the object storage class according to your preferences/policy\n",
    "\n",
    "* Also, you can specify a different Server-side encryption key for the specific document (different from that of S3)\n",
    "\n",
    "Once uploaded, you can check other properties:\n",
    "\n",
    "* Objects are not publicly accessible by default. Select an object and in the tab Properties > Object URL, you will find the public access URL. Try accessing the URL using a browser. An Access Denied error appears!\n",
    "\n",
    "* To make it public, select the object, go to Actions > Make public using ACL. If in grey, it means that ACL is disabled on the bucket. To change this:\n",
    "\n",
    "    - First, go to the Permissions tab, and go to Object Ownership and change it to ACLs enabled. Acknowledge that ACLs will be restored and Save changes\n",
    "\n",
    "    - Then, go back to the Permissions tab and go to Block public access (bucket settings). Uncheck \"Block all public access\" (Do it only when it's really required!) and Save changes.\n",
    "\n",
    "    - Now, you can go again to Actions > Make public using ACL. A successful message should appear!\n",
    "\n",
    "* Check again the public URL to confirm you can access it.\n",
    "\n",
    "**Important**: Even though you've changed the bucket permissions and block public access settings to make the bucket accessible, every object in the bucket is uploaded private (Access denied!) by default.\n",
    "\n",
    "* You need to make it public using the step Actions > Make public using ACL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosting a Website on S3\n",
    "\n",
    "Hosting a website on S3 is a very popular use case! Especially static websites: \n",
    "\n",
    "1. Select the template from tooplate.com: https://www.tooplate.com/view/2137-barista-cafe\n",
    "\n",
    "2. Download the .zip file and extract it (saved in folder AWS > S3-cafe-barista-website).\n",
    "\n",
    "3. We need to create two S3 buckets: \n",
    "\n",
    "    **1st one: website files**\n",
    "\n",
    "    * Choose a unique name: 1st: s3-barista-web\n",
    "\n",
    "    * Enable Bucket Versioning\n",
    "\n",
    "    * Create bucket\n",
    "\n",
    "    * Drag and drop all the website files into this S3 bucket and click on Upload.\n",
    "\n",
    "    2nd one: website access logs \n",
    "\n",
    "    * Choose a unique name: s3-barista-accesslogs\n",
    "\n",
    "    * Simply click on Create bucket\n",
    "\n",
    "4. Make website bucket files public:\n",
    "\n",
    "    * Go to Permissions tab\n",
    "\n",
    "    * Uncheck Block public access settings\n",
    "\n",
    "    * Edit Object Ownership by enabling ACLs\n",
    "\n",
    "    * Go to Objects tab, select all the objects, go to Actions > Make public using ACL and click on Make public\n",
    "\n",
    "    * The website is accessed through the main `index.html` page. S3 gives an option for hosting static websites:\n",
    "\n",
    "        - Go to the Properties tab and scroll down until you find the Static website hosting settings\n",
    "\n",
    "        - Edit to Enable static website hosting\n",
    "\n",
    "        - In Index document, provide the index document `index.html`. We don't have any Error document but give the name `error.html`\n",
    "\n",
    "        - Save changes\n",
    "\n",
    "        - In the Static website hosting settings, you will get a public URL for the website. But, we need to configure the website access log files.\n",
    "\n",
    "    **2nd one: website access logs**\n",
    "\n",
    "    * Choose a unique name: s3-barista-accesslogs\n",
    "\n",
    "5. **Before accessing the website**: Configure the 2nd S3 bucket to store the access logs\n",
    "\n",
    "    * First, configure the s3-barista-web bucket Server access logging in the Properties tab:\n",
    "\n",
    "        - Edit to Enable access logs \n",
    "\n",
    "        - In Destination, specify the bucket: Click on Browse S3, select s3-barista-accesslogs and click on Choose destination\n",
    "\n",
    "        - Keep the default Log object key format and Save changes\n",
    "\n",
    "6. Access the website from the public URL: You will see the website hosted\n",
    "\n",
    "7. Check the access logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle Configuration in S3\n",
    "\n",
    "It's helpful to transition objects from one storage class to another, minimising storage costs.\n",
    "\n",
    "Go to the S3 bucket and the Management tab. Find the Lifecycle rules settings and click on Create lifecycle run:\n",
    "\n",
    "- Define a Lifecycle rule name: CostEffectiveTransitions\n",
    "\n",
    "- Choose a rule scope: Apply to all objects in the bucket (depends on your documents). Acknowledge to apply to all the objects.\n",
    "\n",
    "- Choose Lifecycle rule actions: This is important when you have versioning activated in your S3 bucket. If you want to minimise costs, you will need to do something about the non-current version files (do they get expired or permanently deleted?)\n",
    "\n",
    "    * Move current versions of objects between storage classes: Tick\n",
    "\n",
    "    * Move noncurrent versions of objects between storage classes: Tick when versioning\n",
    "\n",
    "    * Expire current versions of objects: In a non-versioned bucket, expire means delete. In a versioned bucket, it means placing a delete marker\n",
    "\n",
    "    * Permanently delete noncurrent versions of objects: For versioned buckets.\n",
    "\n",
    "    * Delete expired object delete markerers or incomplete multipart uploads.\n",
    "\n",
    "- Transition current versions:\n",
    "\n",
    "    * Choose storage class transitions: E.g., Standard-IA\n",
    "\n",
    "    * Days after object creation: Depends on your use case\n",
    "\n",
    "    And start adding other transitions: One-Zone IA -> Glacier Flexible Retrieval -> Glacier Deep Archive (and define the days)\n",
    "\n",
    "- Transition noncurrent versions: Similar to current versions (omit number of versions)\n",
    "\n",
    "- Expire current versions: Set the number of days after object creation according to your use case\n",
    "\n",
    "- Permanently delete noncurrent versions: Set the number of days after object creation according to your use case\n",
    "\n",
    "- Delete expired object delete markers or incomplete multipart: Tick on Delete incomplete multipart uploads\n",
    "\n",
    "- Create rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replication Rules in S3\n",
    "\n",
    "Used for disaster recovery.\n",
    "\n",
    "Go to the Management tab, find the Replication rules settings and click on Create replication rule:\n",
    "\n",
    "* Set a Replication rule name: DisasterRecoveryBarista\n",
    "\n",
    "* Status: Enabled\n",
    "\n",
    "* In Source bucket, choose a rule scope: \n",
    "\n",
    "    - Limit the scope of this rule using one or more filters: based on your requirements\n",
    "\n",
    "    - Apply to all objects in the bucket\n",
    "\n",
    "* In Destination, choose a bucket in this account or in another account\n",
    "\n",
    "    - Create a new S3 bucket in your account or another account in a different region and enter the bucket name\n",
    "\n",
    "    - Enable versioning in the created bucket\n",
    "\n",
    "* IAM role: Create new role: This creates a permission on the destination bucket so the source bucket copies data in it (tick)\n",
    "\n",
    "* Encryption: In case you want to encrypt using KMS.\n",
    "\n",
    "* Destination storage class: Replicated data won't be accessed frequently, so you want to Change the storage class to, for example, One-Zone IA or Standard-IA\n",
    "\n",
    "* Additional replication options: Make replication faster using Replication Time Control (RTC), for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Relational DataBase Service (RDS)\n",
    "\n",
    "DB Administration:\n",
    "\n",
    "* Installing\n",
    "\n",
    "* Patching\n",
    "\n",
    "* Monitoring\n",
    "\n",
    "* Performance Tuning\n",
    "\n",
    "* Backups\n",
    "\n",
    "* Scaling\n",
    "\n",
    "* Security\n",
    "\n",
    "* Hardware Upgrades\n",
    "\n",
    "* Storage Management \n",
    "\n",
    "### Amazon RDS\n",
    "\n",
    "* Distributed relational database service\n",
    "\n",
    "* High-availability Muli-AZ deployments\n",
    "\n",
    "* Effortless scaling\n",
    "\n",
    "* Read replicas for performance\n",
    "\n",
    "### Creating a RDS\n",
    "\n",
    "Search the RDS in the Services catalog in the Database section\n",
    "\n",
    "RDS supports various database engines like MySQL, PostgreSQL, Oracle. If you are using MySQL or PostgreSQL, AWS recommends using **Amazon Aurora** (5 times faster than MySQL and 3 times faster than PostgreSQL). Aurora also supports up to 64Tb of auto-scaling storage capacity.\n",
    "\n",
    "Click on Create database.\n",
    "\n",
    "* Choose a database creation method: Standard create\n",
    "\n",
    "* Engine options and version: Select according to your use case: MySQL, version 5.7.44\n",
    "\n",
    "* Templates: Choose according to your use case: \n",
    "\n",
    "    - Production vs Dev/Test: Production provides multi AZ, and the EBS storage type is provisioned IOPS (the fastest one).\n",
    "\n",
    "* Settings: \n",
    "\n",
    "    - DB instance identifier: rds-vprofile-mysql\n",
    "\n",
    "    - Credential settings: \n",
    "\n",
    "        * Master username: admin\n",
    "\n",
    "        * Credentials management: Check how Managed in AWS Secrets Manager (most secure). For now, we use Self managed and tick the Auto generate password box.\n",
    "\n",
    "* Instance configuration:\n",
    "\n",
    "    - Memory Optimized classes: For large databases \n",
    "\n",
    "    - Burstable classes: For free tier (db.t3.micro)\n",
    "\n",
    "* Storage: \n",
    "\n",
    "    - Storage type: General Purpose (SSD)\n",
    "\n",
    "    - Allocated storage: 20 GiB\n",
    "\n",
    "    - Storage autoscaling: Enable to a maximum of 1000 GiB\n",
    "\n",
    "* Connectivity:\n",
    "\n",
    "    - Compute resource: Don't connect to an EC2 compute resource\n",
    "\n",
    "    - Network type: IPv4\n",
    "\n",
    "    - Virtual private cloud (VPC): Default VPC\n",
    "\n",
    "    - DB subnet group: default\n",
    "\n",
    "    - Public access: No\n",
    "\n",
    "    - VPC security group (firewalll): Create new\n",
    "\n",
    "    - New VPC security group name: rds-vprofile-sg\n",
    "\n",
    "    - Availability zone: No preference\n",
    "\n",
    "    - Additional configuration: Database port: 3306\n",
    "\n",
    "* Database authentication: Password authentication\n",
    "\n",
    "* Monitoring: Enable and keep defaults\n",
    "\n",
    "* Database options: \n",
    "\n",
    "    - Initial database name: accounts\n",
    "\n",
    "* Backup: Enable automated backups, retention period: 7 days, Copy tags to snapshots (tick)\n",
    "\n",
    "* Backup replication: Enable replication in another AWS Region (Untick for Free Tier)\n",
    "\n",
    "* Encryption: Enable encryption and keep defaults\n",
    "\n",
    "* Log exports: Select them all: Audit, Error, General, Slow\n",
    "\n",
    "* Maintenance: \n",
    "\n",
    "    - Enable if you want minor updates for the MySQL version we chose will be automatically patched.\n",
    "\n",
    "    - Maintenance window: Select window preference if you have any\n",
    "\n",
    "* Deletion protection: Enable if you want to prevent your RDS instance from being deleted accidentally\n",
    "\n",
    "* Check estimated costs and click on Create Database\n",
    "\n",
    "When created, **make sure you copy the credentials, i.e., the password for the master user (admin): eqUrQzgJZEWcwfdhULTk\n",
    "\n",
    "You will also need the Endpoint: rds-vprofile-mysql.cx0uiwkyytbd.us-east-1.rds.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing a RDS\n",
    "\n",
    "To access a database in RDS, we need to create an E2 instance in the same region as the database using the same VPC (see the Connectivity & Security tab your recently created RDS).\n",
    "\n",
    "Go to EC2, make sure you are in the same region (VPC) and click on Launch instance:\n",
    "\n",
    "* Name: ec2-vprofile-db\n",
    "\n",
    "* OS image: Ubuntu Server 22.04 (Free tier eligible)\n",
    "\n",
    "* Create and download a Key pair: kp-vprofile-db.pem \n",
    "\n",
    "* Create a new Security group: vprofile-db-sg\n",
    "\n",
    "    - Type: ssh, Source type: My IP\n",
    "\n",
    "* Launch instance\n",
    "\n",
    "Go back to RDS and find the endpoint for the database instance (Connectivity & security tab).\n",
    "\n",
    "Now, log in the EC2 instance:\n",
    "\n",
    "* Copy Public IPv4 address in the Details tab: 54.235.35.97\n",
    "\n",
    "* Using git bash, go to the directory where the instance Key pair is located (.pem file) and log in: `ssh -i kp-vprofile-db.pem ubuntu@54.235.35.97`\n",
    "\n",
    "* Go to root user and run `apt update` to update the instance\n",
    "\n",
    "* Install MySQL-client: `apt install mysql-client -y`\n",
    "\n",
    "* Access MySQL using the VPC and credentials in the previous section: \n",
    "\n",
    "    `mysql -h rds-vprofile-mysql.cx0uiwkyytbd.us-east-1.rds.amazonaws.com -u admin -peqUrQzgJZEWcwfdhULTk`\n",
    "\n",
    "    - If there are connections problems (EC2 and RDS are not connecting), you can try `telnet rds-vprofile-mysql.cx0uiwkyytbd.us-east-1.rds.amazonaws.com 3306` to check the connection to the VPC on port 3306. \n",
    "    \n",
    "    You will see it's not connecting. This is because the RDS security group is not allowing any connection from the EC2 instance (similar to the ELB exercise)\n",
    "\n",
    "**Fixing connection problem:\n",
    "\n",
    "Go to RDS in AWS:\n",
    "\n",
    "* In the Connectivity & security tab, check Security > VPC security groups\n",
    "\n",
    "    - Click on it and check the Inbound rules (so far, only allows connection from MyIP)\n",
    "\n",
    "    - Edit inbound rules: Remove the current IP and add the following inbound rule:\n",
    "\n",
    "        Type: MYSQL/Aurora, Source: Custom, Search for the EC2 instance security group: sg-077df06bf2a170293 (vprofile-db-sg) OR\n",
    "\n",
    "        Type: MYSQL/Aurora, Source: Custom, Go to your EC2 instance and search for the Private IPv4 addresses: 172.31.27.100/32\n",
    "\n",
    "    - Click on Save rules\n",
    "\n",
    "Go again to the git bash and try the connection between the EC2 instance and the MySQL db.\n",
    "\n",
    "The `mysql >` command should appear.\n",
    "\n",
    "* Run the usual SQL commands and use it to implement your database\n",
    "\n",
    "**Stop the RDS service to reduce computation costs**: Go to RDS and select the database, then go to Actions > Stop"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
